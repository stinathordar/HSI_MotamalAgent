import streamlit as st
import os
from langchain.vectorstores import FAISS
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA

# ğŸŒ OpenAI lykill Ãºr Streamlit secrets
os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]

@st.cache_resource
def hlaÃ°a_leitarkerfi():
    embeddings = OpenAIEmbeddings()
    db = FAISS.load_local("hsi_faiss_index", embeddings, allow_dangerous_deserialization=True)
    return db.as_retriever()

@st.cache_resource
def hlaÃ°a_svarskeÃ°ju():
    retriever = hlaÃ°a_leitarkerfi()
    llm = ChatOpenAI(temperature=0.2, model="gpt-3.5-turbo")
    return RetrievalQA.from_chain_type(llm=llm, retriever=retriever)

qa = hlaÃ°a_svarskeÃ°ju()

st.set_page_config(page_title="HSÃ Regluagent â€“ nÃ¡kvÃ¦mt", page_icon="ğŸ¤¾")
st.title("ğŸ“˜ Regluagent HSÃ â€“ meÃ° venslaleit")
st.markdown("SpurÃ°u Ãºt frÃ¡ reglugerÃ° HSÃ og fÃ¡Ã°u nÃ¡kvÃ¦mt svar Ãºr venslaleitarkerfi.")

spurning = st.text_input("ğŸ’¬ Spurning:")

if st.button("Senda") and spurning:
    svar = qa.run(spurning)
    st.markdown("---")
    st.markdown(f"**Svar:**\n\n{svar}")
